#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd

## Load config and sample sheets 
configfile: "config/config.yaml"

## Extract sample region names from full BED input
sampleInfo = pd.read_csv(config["input"], sep='\t', index_col = "name")
samples = sampleInfo.index

## Define output file names based on parameters
finalOutputSuffix = ''
indexSuffix = ''
kmerSuffix = ''
structureSuffix = ''

if config["kmerFilter"] == True:
    kmerSuffix = '_' + '_'.join(str(x) for x in [config["kmerLength"], config["kmerCount"]])
if config["structureFilter"] == True:
    structureSuffix = '_sC'
if config["addIndex"] == True:
    indexSuffix = '_indexed'
finalOutputSuffix = '_probes' + kmerSuffix + structureSuffix + indexSuffix + '.bed'

## Define bowtie2 and cleaning scripts based on run mode:
if config["alignmentMode"] == "unique":
    bowtieSettings = "--no-hd -t -k 100 --very-sensitive-local"
    outputCleanSettings = "-u"
elif config["alignmentMode"] == "LDA":
    bowtieSettings = "--no-hd -t -k 2 --local -D 20 -R 3 -N 1 -L 20 -i C,4 --score-min G,1,4"
    outputCleanSettings = "-T 42"

## Define actions on success
onsuccess:
    print("oligoMiner completed successfully!")

##### Define rules #####
rule all:
    input:
        [expand("output/{group}{ext}", group=key, ext=finalOutputSuffix) for key in samples]

rule makeBED:
    input:
        bed = config["input"]
    output:
        temp([expand("output/{group}.bed", group=key) for key in samples])
    shell:
        """
        awk 'NR>1 {{print > ("output/" $4 ".bed") }}' {input.bed}
        """

rule getFASTA:
    input:
        bed = "output/{name}.bed"
    output:
        fasta = temp("output/{name}.fa")
    params:
        genome = config['genomeFASTA']
    log:
        err = "output/logs/{name}_getFASTA.err"
    benchmark: 
        "output/benchmarks/{name}_getFASTA.tsv"
    shell:
        """
        module load bedtools
        bedtools getfasta -fi {params.genome} -fo {output.fasta} -bed {input.bed}
        """

rule blockParse:
    input:
        fasta = "output/{name}.fa"
    output:
        fastq = temp("output/{name}.fastq")
    params:
        out = "output/{name}",
        minLength = config["probeLengthMin"],
        maxLength = config["probeLengthMax"]
    log:
        err = "output/logs/{name}_blockParse.err"
    benchmark: 
        "output/benchmarks/{name}_blockParse.tsv"
    conda:
        "probeMining"
    shell:
        """
        python scripts/blockParse.py -l {params.minLength} -L {params.maxLength} -f {input.fasta} -o {params.out}
        """

rule align:
    input:
        fastq = "output/{name}.fastq"
    output:
        sam = temp("output/{name}.sam")
    params:
        index = config["bowtieIndex"],
        settings = bowtieSettings
    log:
        err = "output/logs/{name}_align.err"
    benchmark: 
        "output/benchmarks/{name}_align.tsv"
    conda:
        "probeMining"
    shell:
        """
        bowtie2 -x {params.index} -U {input.fastq} {params.settings} -S {output.sam}
        """

rule outputClean:
    input:
        sam = "output/{name}.sam"
    output:
        probes = "output/{name}_probes.bed"
    params:
        settings = outputCleanSettings
    log:
        err = "output/logs/{name}_outputClean.err"
    benchmark: 
        "output/benchmarks/{name}_outputClean.tsv"
    conda:
        "probeMining"
    shell:
        """
        python scripts/outputClean.py {params.settings} -f {input.sam}
        """

rule kmerFilter:
    input:
        probes = "output/{name}_probes.bed"
    output:
        filtered = "output/{name}_probes" + kmerSuffix + ".bed"
    params:
        jf = config["jellyfishIndex"],
        kmerLength = str(config["kmerLength"]),
        kmerCount = str(config["kmerCount"])
    log:
        err = "output/logs/{name}_kmerFilter.err"
    benchmark: 
        "output/benchmarks/{name}_kmerFilter.tsv"
    conda:
        "probeMining"
    shell:
        """
        python scripts/kmerFilter.py -f {input.probes} -m {params.kmerLength} -j {params.jf} -k {params.kmerCount}
        """

rule structureCheck:
    input:
        probes = "output/{name}_probes" + kmerSuffix + ".bed"
    output:
        filtered = "output/{name}_probes" + kmerSuffix + "_sC.bed"
    params:
        thresh = config["structureThresh"]
    log:
        err = "output/logs/{name}_structureCheck.err"
    benchmark: 
        "output/benchmarks/{name}_structureCheck.tsv"
    conda:
        "probeMining"
    shell:
        """
        python scripts/structureCheck.py -f {input.probes} -t {params.thresh}
        """

rule indexStitch:
    input:
        probes = "output/{name}_probes" + kmerSuffix + structureSuffix + ".bed"
    output:
        indexed = "output/{name}_probes" + kmerSuffix + structureSuffix + "_indexed.bed"
    params:
        indexSeqs = config["indexSeqs"],
        uniF = lambda wildcards: sampleInfo.loc[wildcards.name, 'uniF'],
        uniR = lambda wildcards: sampleInfo.loc[wildcards.name, 'uniR'],
        barcodes = lambda wildcards: sampleInfo.loc[wildcards.name, 'barcodes']
    log:
        err = "output/logs/{name}_indexStitch.err"
    benchmark: 
        "output/benchmarks/{name}_indexStitch.tsv"
    conda:
        "probeMining"
    shell:
        """
        python scripts/addIndex.py -i {input.probes} --uniF {params.uniF} --uniR {params.uniR} --barcodes {params.barcodes} --indexInfo {params.indexSeqs}
        """